
## day01

MR最核心的思想：分而治之
- 分布式批处理计算必然要分阶段，第二阶段的task能否运行取决于第一阶段的task是否完成
- 必然需要通过网络来执行数据混洗：把标记相同的value传输到同一台节点，启动Task来执行聚合计算

#### MR引擎
- Mapper不是用来做计算的，而是用来给第二阶段的计算做准备的。
> mapper做计算是谓词下推的体现。reducer的计算，有一些可以提前到mapper端完成
- Reducer 真正做计算的地方

分布式批计算引擎：**分布式分阶段并行执行引擎**

经典面试题：大文件中，找到top50
- map：大文件切分成n个小文件，每个文件通过大顶堆保留50条数据
- reduce：将每个小文件所保留的50条数据，再通过堆保留最终的50条数据

框架：半成品，把很多应用持续的公共部分做抽象和沉淀
比如：MR就是


#### Spark引擎

Spark相对于MR的真正优势（原理上的优势）：
- DAG引擎
- 每个阶段产出的数据集支持做持久化（RDD的持久化）

> 说spark的优势是基于内存的计算，这个说法不合适。因为本质来说，分布式计算都是迭代

> Simple Fast scalable unified



总结：计算引擎
【计算】引擎
***重点就在计算***
1.怎么计算？——分布式计算[分而治之]
2.怎么分？——分开部署计算[分多个'链']、分阶段
3.怎么分阶段？——分两个阶段[数据准备]、[数据计算]
4.怎么做数据准备？——读取数据[按照规定的接口读取数据]、按照计算需求读取数据
5.怎么计算数据？——按照业务需求计算数据[计算最大值、求交集、并集、差… …]

#### Flink引擎

流批一体从最简单处讲，就是一个if else，很多公司就是通过这种方式封装了流批一体平台（离线用spark，实时用flink）

flink1.13版本的流批一体实际还不是很完善

（yarn特殊的点：2层资源调度模型。资源者申请到资源之后，怎么用这个资源，资源管理者不关心也管不到。）


## day02
day01最核心的内容：分阶段并行执行（flink中的并行度的概念 ）